{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOf97GZj0HJLMwDc342XUSL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **순환 신경망**"],"metadata":{"id":"yxDfWaQHmAZG"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"LyhuHsglaevb","executionInfo":{"status":"ok","timestamp":1746082065244,"user_tz":-540,"elapsed":12,"user":{"displayName":"장윤서","userId":"03408249735788435458"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.datasets import imdb"]},{"cell_type":"code","source":["(x_train_all, y_train_all) , (x_test, y_test) = imdb.load_data(skip_top=20, num_words=100)\n","#매개변수 skip_top: 가장 많이 등장한 단어(ex: a, is, the...등 분석에 유용하지 않은 것들) 중 건너뛸 단어의 개수\n","#매개변수 num_words: 훈련에 사용할 단어의 개수"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFE1FVQ9mSz4","executionInfo":{"status":"ok","timestamp":1746082204217,"user_tz":-540,"elapsed":4397,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"d9224734-2e0a-4917-c10a-72cf2389701c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["print(x_train_all.shape, y_train_all.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w64RlASfnAEq","executionInfo":{"status":"ok","timestamp":1746082217651,"user_tz":-540,"elapsed":11,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"bc1cd1f6-e077-4da2-cc27-11908a00b64b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(25000,) (25000,)\n"]}]},{"cell_type":"code","source":["print(x_train_all[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsOydQLrnD26","executionInfo":{"status":"ok","timestamp":1746082421456,"user_tz":-540,"elapsed":11,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"29963d46-e265-4a95-f405-263860f6060f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 2, 22, 2, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 2, 2, 36, 2, 2, 25, 2, 43, 2, 2, 50, 2, 2, 2, 35, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 39, 2, 2, 2, 2, 2, 2, 38, 2, 2, 2, 2, 50, 2, 2, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 22, 71, 87, 2, 2, 43, 2, 38, 76, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 2, 2, 2, 2, 62, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 66, 2, 33, 2, 2, 2, 2, 38, 2, 2, 25, 2, 51, 36, 2, 48, 25, 2, 33, 2, 22, 2, 2, 28, 77, 52, 2, 2, 2, 2, 82, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 2, 2, 2, 2, 2, 2, 88, 2, 2, 2, 2, 98, 32, 2, 56, 26, 2, 2, 2, 2, 2, 2, 2, 22, 21, 2, 2, 26, 2, 2, 2, 30, 2, 2, 51, 36, 28, 2, 92, 25, 2, 2, 2, 65, 2, 38, 2, 88, 2, 2, 2, 2, 2, 2, 2, 2, 32, 2, 2, 2, 2, 2, 32]\n"]}]},{"cell_type":"code","source":["#0,1,2 제외\n","for i in range(len(x_train_all)) :\n","  x_train_all[i] = [ w for w in x_train_all[i] if w>2 ]\n","\n","print(x_train_all[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbP0wHBan3Qe","executionInfo":{"status":"ok","timestamp":1746082723504,"user_tz":-540,"elapsed":237,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"dc765973-c7e5-4b63-f1e7-1f83870ad3e2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[22, 43, 65, 66, 36, 25, 43, 50, 35, 39, 38, 50, 22, 22, 71, 87, 43, 38, 76, 22, 62, 66, 33, 38, 25, 51, 36, 48, 25, 33, 22, 28, 77, 52, 82, 36, 71, 43, 26, 46, 88, 98, 32, 56, 26, 22, 21, 26, 30, 51, 36, 28, 92, 25, 65, 38, 88, 32, 32]\n"]}]},{"cell_type":"code","source":["#어휘사전 내려받기(정수->영단어) / get_word_index(): { '영단어':정수 } 딕셔너리 반환\n","word_to_index = imdb.get_word_index()\n","print(word_to_index['movie'])\n","\n","index_to_word = {word_to_index[k]: k for k in word_to_index}\n","print(index_to_word[17])\n","\n","for w in x_train_all[0] :\n","  print(index_to_word[w-3], end=' ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nk1gPXVvpoAo","executionInfo":{"status":"ok","timestamp":1746083521905,"user_tz":-540,"elapsed":118,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"9b534906-8e66-4b12-ea59-046428594af6"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["17\n","movie\n","film just story really they you just there an from so there film film were great just so much film would really at so you what they if you at film have been good also they were just are out because them all up are film but are be what they have don't you story so because all all "]}]},{"cell_type":"code","source":["#1:긍정, 0:부정\n","print(y_train_all[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snC8aUAVsSuT","executionInfo":{"status":"ok","timestamp":1746083626464,"user_tz":-540,"elapsed":3,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"0edbdaa5-1e60-42ac-ece3-a0cbdb7853d4"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 0 0 1 0 1 0]\n"]}]},{"cell_type":"code","source":["np.random.seed(42)\n","random_index = np.random.permutation(25000) #25000 이하의 순서 랜덤\n","\n","x_train = x_train_all[random_index[:20000]]\n","y_train = y_train_all[random_index[:20000]]\n","x_val = x_train_all[random_index[20000:]]\n","y_val = y_train_all[random_index[20000:]]"],"metadata":{"id":"__TZFt8dsbzu","executionInfo":{"status":"ok","timestamp":1746083876066,"user_tz":-540,"elapsed":9,"user":{"displayName":"장윤서","userId":"03408249735788435458"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["#각 리뷰의 길이 - 차이가 있음\n","print(len(x_train_all[0]), len(x_train_all[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHpb-ZJ0qGRA","executionInfo":{"status":"ok","timestamp":1746083589263,"user_tz":-540,"elapsed":7,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"f3abccf2-71bf-45c2-e08c-12e0bacbcb7b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["59 32\n"]}]},{"cell_type":"code","source":["#길이 맞추기\n","from tensorflow.keras.preprocessing import sequence\n","\n","maxlen = 100\n","x_train_seq = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_val_seq = sequence.pad_sequences(x_val, maxlen=maxlen)\n","\n","print(x_train_seq.shape, x_val_seq.shape)\n","print(x_train_seq[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csGI7QRttYvm","executionInfo":{"status":"ok","timestamp":1746084152221,"user_tz":-540,"elapsed":219,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"fba6023d-4076-44cf-ed75-a17139668c34"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["(20000, 100) (5000, 100)\n","[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0 35 40 27 28 40 22 83 31 85 45\n"," 24 23 31 70 31 76 30 98 32 22 28 51 75 56 30 33 97 53 38 46 53 74 31 35\n"," 23 34 22 58]\n"]}]},{"cell_type":"code","source":["#원-핫 인코딩하기\n","from tensorflow.keras.utils import to_categorical\n","x_train_onehot = to_categorical(x_train_seq)\n","x_val_onehot = to_categorical(x_val_seq)\n","\n","print(x_train_onehot.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_cptxX-uSdG","executionInfo":{"status":"ok","timestamp":1746084418558,"user_tz":-540,"elapsed":1273,"user":{"displayName":"장윤서","userId":"03408249735788435458"}},"outputId":"ad849feb-d1e3-491b-e23b-51cfca3a089c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["(20000, 100, 100)\n"]}]},{"cell_type":"code","source":["#순환 신경망 클래스 구현하기\n","class RecurrentNetwork :\n","\n","  def __init__(self, n_cells=10, batch_size=32, learning_rate=0,1) :\n","    self.n_cells = n_cells #셀 개수(순환층 뉴런 개수)\n","    self.batch_size = batch_size\n","    self.w1h = None #은닉상태에 대한 가중치\n","    self.w1x = None #입력에 대한 가중치\n","    self.b1 = None #순환층의 절편\n","    self.w2 = None #출력층의 가중치\n","    self.b2 = None #출력층의 절편\n","    self.h = None #순환층의 활성화 출력 저장\n","    self.losses = []\n","    self.val_losses = []\n","    self.lr = learning_rate\n","\n","\n","  def forpass(self, x) :\n","    self.h = [ np.zeros((x.shape[0], self.n_cells)) ] #은닉상태 초기화\n","    seq = np.swapaxes(x, 0, 1) #샘플개수 - 타임스텝 차원 바꿈\n","    for x in seq : #모든 단어(원핫코딩)에 대하여\n","      z1 = np.dot(x, self.w1x) + np.dot(self.h[-1], self.w1h) + self.b1 #순환층 선형 계산(X*Wx + H*Wh + b1)\n","      h = np.tanh(z1) #순환층 활성화 출력\n","      self.h.append(h) #활성화 출력값, 즉 전 타임스텝 은닉상태값 저장\n","      z2 = np.dot(h, self.w2) + self.b2 #출력층 선형 계산\n","    return z2\n","\n","\n","  def backprop(self, x, err) :\n","    m = len(x)\n","\n","    w2_grad = np.dot(self.h[-1].T, err) / m #출력층 가중치 그레이디언트\n","    b2_grad = np.sum(err) / m #출력층 절편 그레이디언트\n","\n","    seq = np.swapaxes(x, 0, 1) #샘플개수-타임스텝 차원 바꿈\n","\n","    w1h_grad = w1x_grad = b1_grad = 0 #순환층 가중치들 초기화\n","    err_to_cell = np.dot(err, self.w2.T) * (1 - self.h[-1] ** 2) #순환층 전까지 미분값(그레이디언트값)\n","    for x, h in zip( seq[::-1][:10], self.h[:-1][::-1][:10] ) : #최근 타임스텝부터(뒤집기), 10개 타임스텝만 / 직전 은닉상태는 err_to_cell에 썼으므로 1개뺴고\n","      w1h_grad += np.dot(h.T, err_to_cell) #은닉상태 가중치 추가\n","      w1x_grad += np.dot(x.T, err_to_cell) #입력 가중치 추가\n","      b1_grad += np.sum(err_to_cell, axis=0) #순환층 절편 추가\n","      err_to_cell = np.dot(err_to_cell, self.w1h) * (1 - h ** 2) #이전 타임스텝의 순환층_전_그레이디언트값 계산\n","\n","    w1h_grad /= m\n","    w1x_grad /= m\n","    b1_grad /= m\n","\n","    return w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad\n","\n","\n","  def sigmoid(self, z) :\n","    a = 1 / (1 + np.exp(-z))\n","    return a\n","\n","\n","  def init_weights(self, n_features, n_classes) :\n","    orth_init = tf.initializers.Orthogonal() #순환 신경망에서 쓸 직교 행렬 초기화\n","    glorot_init = tf.initializers.GlorotUniform() #출력층에서 쓸 글로럿 초기화\n","\n","    self.w1h = orth_init( (self.n_cells, self.n_cells) ).numpy() #은닉상태 가중치 - (셀 개수, 셀 개수)\n","    self.w1x = glorot_init( (n_features, self.n_cells) ).numpy() #입력 가중치 - (특성개수, 셀 개수)\n","    self.b1 = np.zeros( self.n_cells ) #순환층 절편 - 셀 개수\n","    self.w2 = glorot_init( (self.n_cells, n_classes) ).numpy() #출력층 가중치 - (셀 개수, 클래스 개수)\n","    self.b2 = np.zeros( n_classes ) #출력층 절편 - 클래스 개수\n","\n","\n","  def fit(self, x, y, epochs=100, x_val=None, y_val=None) :\n","    y = y.reshape(-1,1)\n","    y_val = y_val.reshape(-1,1)\n","    np.random.seed(42)\n","    self.init_weights(x.shape[2], y.shape[1]) #가중치 초기화\n","    for i in range(epochs) :\n","      print('에포크', i, end=' ')\n","      batch_losses = []\n","      for x_batch, y_batch in self.gen_batch(x,y) :\n","        print('.', end='')\n","        a = self.training(x_batch, y_batch)\n","        a = np.clip(a, 1e-10, 1-1e-10)\n",""],"metadata":{"id":"_qBGCycJvc4O"},"execution_count":null,"outputs":[]}]}