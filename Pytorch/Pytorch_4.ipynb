{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **4장. 딥러닝 시작**\n",
        "\n",
        "**4.1 인공 신경망의 한계와 딥러닝의 출현**\n",
        "\n",
        "\n",
        "**4.2 딥러닝 구조**\n",
        "\n",
        "    4.2.1 딥러닝 용어\n",
        "    4.2.2 딥러닝 학습\n",
        "    4.2.3 딥러닝의 문제점과 해결 방안\n",
        "    4.2.4 딥러닝을 사용할 때 이점\n",
        "\n",
        "**4.3 딥러닝 알고리즘**\n",
        "\n",
        "    4.3.1 심층 신경망\n",
        "    4.3.2 합성곱 신경망\n",
        "    4.3.3 순환 신경망\n",
        "    4.3.4 제한된 볼츠만 머신\n",
        "    4.3.5 심층 신뢰 신경망\n",
        "\n",
        "**4.4 우리는 무엇을 배워야 할까?**"
      ],
      "metadata": {
        "id": "CAbKC_shgJT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1 인공 신경망의 한계와 딥러닝 출현\n",
        "단층 퍼셉트론만으로는 논리게이트 AND, OR만 구현이 되고 XOR는 1단으로 구현이 안됨\n",
        "\n",
        "-> 다층 퍼셉트론(multi-layer perceptron): 입력층과 출력층 사이에 하나 이상의 중간층(은닉층)을 둔 퍼셉트론\n",
        "\n",
        "-> 심층 신경망(Deep Neural Network, DNN): 입력층과 출력층 사이에 은닉층이 여러 개 있는 신경망\n",
        "\n",
        "이때, 심층 신경망을 다른 이름으로 **딥러닝**이라 한다."
      ],
      "metadata": {
        "id": "tbKY4q7tlIL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2.1 경사 하강법의 용어\n",
        "\n",
        "경사 하강법의 종류\n",
        "1. 배치 경사 하강법 : 한 에포크에 전체 훈련 데이터 세트에 대하여 기울기 계산\n",
        "\n",
        "  - 학습이 오래 걸림\n",
        "\n",
        "2. 확률적 경사 하강법 : 임의로 선택한 데이터에 대해 기울기 계산\n",
        "\n",
        "  - 파라미터 변경 폭 불안정하고, 때로는 배치 경사 하강법보다 정확도가 낮을 수도 있음\n",
        "  - 속도가 빠름\n",
        "\n",
        "3. 미니 배치 경사 하강법 : 전체 데이터를 미니 배치로 나누어서, 미니 배치 한 개마다 기울기 계산하여 평균 기울기로 업데이트\n",
        "\n",
        "  - 배치 경사 하강법보다 속도가 빠름\n",
        "  - 확률적 경사 하강법보다 안정적"
      ],
      "metadata": {
        "id": "vkv-4U0Gy4V8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 딥러닝 알고리즘\n",
        "\n",
        "**4.3.1 심층 신경망 (DNN, Deep Neural Network)**\n",
        "\n",
        ": 입력층과 출력층 사이에 다수의 은닉층을 포함하는 인공 신경망\n",
        "\n",
        "- 장점 : 다수의 은닉층을 추가했기 때문에, 별도의 트릭(trick) 없이 비선형 분류가 가능함\n",
        " (머신려닝에서 비선형 분류를 하기 위해 여러 트릭을 사용했던 것과는 달리~)\n",
        "\n",
        "- 단점 : 그러나 학습을 위한 연산량이 많고 기울기 소멸 문제가 발생할 수 있음 -> 드롭아웃, 렐루 함수, 배치 정규화 등 적용 필요\n",
        "\n",
        "\n",
        "**4.3.2 합성곱 신경망 (CNN, Convolutional Neural Neetwork)**\n",
        "\n",
        ": 합성곱층(convolutional layer)과 풀링층(pooling layer)을 포함하는, 이미지 처리 성능이 뛰어난 인공 신경망 알고리즘\n",
        "\n",
        "  - 각 층의 입출력 형상 유지\n",
        "  - 이미지의 공간 정보를 유지하면서, 인접 이미지와 차이가 있는 특징을 효과적으로 인식\n",
        "  - 복수 필터로 이미지의 특징을 추출하고 학습함\n",
        "  - 추출한 이미지의 특징을 모으고 강화하는 풀링층이 있음\n",
        "  - 필터를 공유 파라미터로 사용하기 때문에, 일반 인공 신경망과 비교하여 학습 피라미터가 매우 적음\n",
        "\n",
        "\n",
        "**4.3.3 순환 신경망(RNN, Recurrent Neural Network)**\n",
        "\n",
        ": 시계열 데이터(음악, 영상 등) 같은, 시간 흐름에 따라 변화하는 데이터를 학습하기 위한 인공 신경망\n",
        "\n",
        "  - 시간성(temporal property)을 가진 데이터가 많음\n",
        "  - 시가성 정보를 이용하여 데이터의 특징을 잘 다룸\n",
        "  - 시간에 따라 내용이 변하므로 -> 데이터는 동적이고, 길이가 가변적임\n",
        "  - 단점 : 기울기 소멸 문제로 학습이 제대로 되지 않는 문제가 있음 -> LSTM(Long-Short Term Memoy / 망각 게이트, 입력 게이트, 출력 게이트) 많이 사용\n",
        "  - 자연어 처리 분야에서 성능 좋음(언어 모델링, 텍스트 생성, 자동 번역(기계 번역), 음성 인식, 이미지 캡션 생성 등)\n",
        "\n",
        "\n",
        "**4.3.4 제한된 볼츠만 머신(RBM, Restricted Boltzmann machine)**\n",
        "\n",
        ":가시층(visible layer)과 은닉층(hidden layer)으로 구성되어, 가시층에서 은닉층으로만 연결되는 구조\n",
        "\n",
        "  - 볼츠만 머신 : 모든 신경망의 뉴런들이 서로 연결되어 있는 완전 그래프의 구조\n",
        "  - 차원 감소, 분류, 선형 회귀 분석, 협업 필터링(collaborative filtering), 특성 값 학습(feature learning), 주제 모델링(topic modelling)에 사용\n",
        "  - 기울기 소멸 문제를 해결하기 우히ㅏ여, 사전 학습 용도로 활용 가능\n",
        "  - 심층 신뢰 신경망(DBN)의 요소로 활용\n",
        "\n",
        "\n",
        "**4.3.5 심층 신뢰 신경망(DBN, Deep Belief Network)**\n",
        "\n",
        ": 사전 훈련이 되어 있는 제한된 볼츠만 머신을 여러 층으로 쌓은 형태로 연결된 신경망\n",
        "\n",
        "- 학습 절차\n",
        "    1. 가시층과 은닉층 2에 제한된 볼츠만 머신을 사전 훈련\n",
        "    2. 첫 번째 층 입력 데이터와 파라미터를 고정하여, 두 번째 층 제한된 볼츠만 머신을 사전 훈련\n",
        "    3. 원하는 층 개수만큼 제한된 볼츠만 머신을 쌓아 올려 전체 DBN 완성\n",
        "- 비지도 학습(레이블이 없는 데이터)\n",
        "- 위로 올라갈수록 추상적 특성 추출 -> 부분적 이미지에서 전체를 연상하는 일반화와 추상화 과정을 구현할 때 유용\n",
        "- 학습된 가중치를 다층 퍼셉트론의 가중치 초깃값으로 사용"
      ],
      "metadata": {
        "id": "l0YOyftg22XB"
      }
    }
  ]
}